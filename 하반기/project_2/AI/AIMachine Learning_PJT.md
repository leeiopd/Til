# AI/Machine Learning



## 프로젝트 개요

* 목표
  * AL/ML의 전반적인 이해
  * 자연어 처리기능을 갖는 챗봇 구현
    * 자연어 처리 기능 구현
    * DNN(Deep Neural Network)구조 파악 및 이를 활용한 챗봇 모델 구현
  * 팀 프로젝트를 통한 협업으로 확장된 기능 구현
    * 트위터 기반을 벗어나 원하는 데이터 셋으로 변경
    * 대화를 통해 감정을 완화해주는 챗본
    * 화자를 기억해서 대화를 하는 챗봇
    * BERT 모델을 활용하여 더욱 인텔리전트한 대답 구현이 가능한 모델 구현

## 머신러닝

* 인공지능의 연구 분야 중 하나로, 인간의 학습 능력과 같은 기능을 컴퓨터에서 실현하고자 하는 기술 및 기법
* 순서나 이유를 명확하게 설명하지 모하는 일을 처리하기 위한 방법
* 분류
  * 학습 데이터에 레이블이 있는 경우와 그렇지 않은 경우에따라 지도 학습과 비지도 학습으로 구분하고, 강화 학습은 지도학습 중 하나로 분류되거나 독립적인 세 번째 머신러닝 모델로 분류하기도 한다.
  * 지도 학습
    * Label이 있는 학습 데이터를 이용해서 학습
    * 분류 - Discrete label data
    * 회귀(Regression) - Continuous label data, 수치 예측에서 많이 사용
  * 비지도 학습
    * 이상 탐지 - 기존 데이터 패턴과 다른 이상치 검출
    * 시각화 - 데이터 특성을 시각화 하여 데이터들의 패턴 연구
    * 차원 축소
  * 강화 학습
    * 어떤 환경 안에서 정의된 에이전트가 현재의 상태를 인식하여, 선택 가능한 행동들 중 보상을 최대화하는 행동 혹은 순서를 선택하는 방법이다.
    * 과적합
      * 과적합을 피하는 방법
        1. 학습 데이터 일부를 다로 떼어내어 학습이 아닌 검증용으로 사용하는 기법
        2. 교차 검증



## 자연어 처리 NLP(Natural Language Process)

* 자연어 처리란
  * 컴퓨터 과학, 인공지능 과 언어학이 합쳐진 분야로 자연어를 컴퓨터에서 분석하고 처리함.
* 자연어 처리의 목적
  * 대량의 자연어 데이터 처리 (문자 종류의 빈도 분포, 언어의 종류와 수, 문서 분류)
  * 컴퓨터에 자연어를 이해시키는 자연어 이해 시스템
* 자연어 처리 모델
  * Classical NLP
  * Deep Leanrning
* 자연어 전 처리 과정
  * Noise canceling - 스펠링 체크 및 띄어쓰기 오류교정
  * Tokenizing - 문장으로 토큰을 나눔, 토큰은 n-gram, 어절, 단어 등으로 목적에 따라 다르게 정의
  * Part-of-Speech tagging - 주어진 토큰의 품사 판별
  * Filtering - 불필요한 단어 제거
  * Term vector representation - (문서, 단어) 행렬에서 각 단어의 중요도를 조절
  * Transformations - TF-IDF 등의 방식으로 term vector 변환



## 딥 러닝

* 컴퓨터가 스스로 학습할 수 있게 하기 위해 인공 신경망을 기반으로 하는 기계학습 기술

* 인간의 신경망 이론을 이용한 인공 신경망의 일종으로, 계층 구조로 구성되면서 입력층과 출력층 사이에 하니 이상의 은닉층을 가지고 있는 심층 신경망이다.

* 예외 처리를 할 필요가 없는 가능한 모든 경우에 대비하기 위해서 필요.

* 퍼셉트론
  * x1, x2 : 입력
  * w1, w2: 가중치
  * y: 출력
  * B: bias
  * y = (w1 * x1) + (w2 * x2) + B
  
* 다층 퍼셉트론

  * 다층 퍼셉츠론으로 XOR 연산 가능

  * 여전히 남은 문제점

    1. 비선형 분류의 어려움

    2. 다층으로 쌓아 올린 퍼셉트론의 학습 방법 부재

       빙하기 돌입.....

* Back Propagation

  * 완료후 역과적으로 돌아오는 과정을 반복해서 학습 시킴

* 발전 과정

  * 알고리즘의 개선
    * MLP
    * Back propagation
    * Vanishing gradient solution
  * 하드웨어의 개선
    * GPU 발전
  * 빅데이터



